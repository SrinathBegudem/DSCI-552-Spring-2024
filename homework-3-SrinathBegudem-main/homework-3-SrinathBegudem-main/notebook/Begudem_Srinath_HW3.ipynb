{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e03645ab",
   "metadata": {},
   "source": [
    "### USC ID  : 8534717045\n",
    "### NAME   : SRINATH BEGUDEM\n",
    "### GITHUB: SrinathBegudem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c180edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm_api\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from itertools import cycle\n",
    "from scipy import interp\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import statistics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef63e523",
   "metadata": {},
   "source": [
    "1.Time Series Classification Part 1: Feature Creation/Extraction\n",
    "An interesting task in machine learning is classification of time series. In this problem,\n",
    "we will classify the activities of humans based on time series obtained by a Wireless\n",
    "Sensor Network.\n",
    "* (a) Download the AReM data from:\n",
    "https://archive.ics.uci.edu/ml/datasets/Activity+Recognition+system+based+on+Multisensor+data+fusion+\\%28AReM\\\n",
    "%29. The dataset contains 7 folders that represent seven types of activities. In\n",
    "each folder, there are multiple files each of which represents an instant of a human\n",
    "performing an activity.\n",
    "1\n",
    "Each file containis 6 time series collected from activities\n",
    "of the same person, which are called avg\n",
    "rss12, var\n",
    "rss12, avg\n",
    "rss13, var\n",
    "rss13,\n",
    "vg\n",
    "rss23, and ar\n",
    "rss23. There are 88 instances in the dataset, each of which con-\n",
    "tains 6 time series and each time series has 480 consecutive values.\n",
    "* b)\n",
    "Keep datasets 1 and 2 in folders bending1 and bending 2, as well as datasets 1,\n",
    "2, and 3 in other folders as test data and other datasets as train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b1314ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total datasets in test data: 19\n",
      "Total datasets in train data: 69\n"
     ]
    }
   ],
   "source": [
    "def load_data_from_folder(foldername, start, end):\n",
    "    file_paths = []\n",
    "\n",
    "    for i in range(start, end + 1):\n",
    "        file_path = f\"{foldername}\\\\dataset{i}.csv\"\n",
    "        file_paths.append(file_path)\n",
    "\n",
    "    data_frames = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(\n",
    "            file_path,\n",
    "            skiprows=5,\n",
    "            on_bad_lines=\"skip\",\n",
    "            header=None,\n",
    "            index_col=None,\n",
    "            names=['time', 'avg_rss12', 'var_rss12', 'avg_rss13', 'var_rss13', 'avg_rss23', 'var_rss23']\n",
    "        )\n",
    "        data_frames.append(df)\n",
    "\n",
    "    concatenated_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    total_datasets = end - start + 1\n",
    "\n",
    "    return concatenated_df, total_datasets\n",
    "\n",
    "root_dir = '..\\AReM'\n",
    "\n",
    "\n",
    "bending1_test_data, bending1_test_total = load_data_from_folder(os.path.join(root_dir, 'bending1'), 1, 2)\n",
    "bending2_test_data, bending2_test_total = load_data_from_folder(os.path.join(root_dir, 'bending2'), 1, 2)\n",
    "cycling_test_data, cycling_test_total = load_data_from_folder(os.path.join(root_dir, 'cycling'), 1, 3)\n",
    "lying_test_data, lying_test_total = load_data_from_folder(os.path.join(root_dir, 'lying'), 1, 3)\n",
    "sitting_test_data, sitting_test_total = load_data_from_folder(os.path.join(root_dir, 'sitting'), 1, 3)\n",
    "standing_test_data, standing_test_total = load_data_from_folder(os.path.join(root_dir, 'standing'), 1, 3)\n",
    "walking_test_data, walking_test_total = load_data_from_folder(os.path.join(root_dir, 'walking'), 1, 3)\n",
    "\n",
    "bending1_train_data, bending1_train_total = load_data_from_folder(os.path.join(root_dir, 'bending1'), 3, 7)\n",
    "bending2_train_data, bending2_train_total = load_data_from_folder(os.path.join(root_dir, 'bending2'), 3, 6)\n",
    "cycling_train_data, cycling_train_total = load_data_from_folder(os.path.join(root_dir, 'cycling'), 4, 15)\n",
    "lying_train_data, lying_train_total = load_data_from_folder(os.path.join(root_dir, 'lying'), 4, 15)\n",
    "sitting_train_data, sitting_train_total = load_data_from_folder(os.path.join(root_dir, 'sitting'), 4, 15)\n",
    "standing_train_data, standing_train_total = load_data_from_folder(os.path.join(root_dir, 'standing'), 4, 15)\n",
    "walking_train_data, walking_train_total = load_data_from_folder(os.path.join(root_dir, 'walking'), 4, 15)\n",
    "\n",
    "combined_test_data = pd.concat([\n",
    "    bending1_test_data,\n",
    "    bending2_test_data,\n",
    "    cycling_test_data,\n",
    "    lying_test_data,\n",
    "    sitting_test_data,\n",
    "    standing_test_data,\n",
    "    walking_test_data\n",
    "])\n",
    "\n",
    "combined_train_data = pd.concat([\n",
    "    bending1_train_data,\n",
    "    bending2_train_data,\n",
    "    cycling_train_data,\n",
    "    lying_train_data,\n",
    "    sitting_train_data,\n",
    "    standing_train_data,\n",
    "    walking_train_data\n",
    "])\n",
    "\n",
    "total_test = sum([\n",
    "    bending1_test_total,\n",
    "    bending2_test_total,\n",
    "    cycling_test_total,\n",
    "    lying_test_total,\n",
    "    sitting_test_total,\n",
    "    standing_test_total,\n",
    "    walking_test_total\n",
    "])\n",
    "\n",
    "total_train = sum([\n",
    "    bending1_train_total,\n",
    "    bending2_train_total,\n",
    "    cycling_train_total,\n",
    "    lying_train_total,\n",
    "    sitting_train_total,\n",
    "    standing_train_total,\n",
    "    walking_train_total\n",
    "])\n",
    "\n",
    "print(f\"Total datasets in test data: {total_test}\")\n",
    "print(f\"Total datasets in train data: {total_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c65a40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>33.75</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>23.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>39.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>39.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>118750</td>\n",
       "      <td>36.00</td>\n",
       "      <td>2.45</td>\n",
       "      <td>17.00</td>\n",
       "      <td>5.10</td>\n",
       "      <td>20.50</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>119000</td>\n",
       "      <td>34.33</td>\n",
       "      <td>1.89</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2.45</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>119250</td>\n",
       "      <td>33.00</td>\n",
       "      <td>7.35</td>\n",
       "      <td>14.60</td>\n",
       "      <td>3.14</td>\n",
       "      <td>13.00</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>119500</td>\n",
       "      <td>31.67</td>\n",
       "      <td>1.25</td>\n",
       "      <td>11.00</td>\n",
       "      <td>6.16</td>\n",
       "      <td>19.25</td>\n",
       "      <td>2.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>119750</td>\n",
       "      <td>30.75</td>\n",
       "      <td>10.21</td>\n",
       "      <td>11.75</td>\n",
       "      <td>1.09</td>\n",
       "      <td>18.50</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9120 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  var_rss23\n",
       "0          0      39.25       0.43      22.75       0.43      33.75       1.30\n",
       "1        250      39.25       0.43      23.00       0.00      33.00       0.00\n",
       "2        500      39.25       0.43      23.25       0.43      33.00       0.00\n",
       "3        750      39.50       0.50      23.00       0.71      33.00       0.00\n",
       "4       1000      39.50       0.50      24.00       0.00      33.00       0.00\n",
       "...      ...        ...        ...        ...        ...        ...        ...\n",
       "1435  118750      36.00       2.45      17.00       5.10      20.50       0.87\n",
       "1436  119000      34.33       1.89      15.00       2.45      17.00       2.12\n",
       "1437  119250      33.00       7.35      14.60       3.14      13.00       5.70\n",
       "1438  119500      31.67       1.25      11.00       6.16      19.25       2.17\n",
       "1439  119750      30.75      10.21      11.75       1.09      18.50       3.20\n",
       "\n",
       "[9120 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b11bde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>21.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>41.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20.25</td>\n",
       "      <td>1.48</td>\n",
       "      <td>31.25</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>41.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>14.25</td>\n",
       "      <td>1.92</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>40.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>15.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>20.00</td>\n",
       "      <td>2.74</td>\n",
       "      <td>32.75</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5755</th>\n",
       "      <td>118750</td>\n",
       "      <td>34.50</td>\n",
       "      <td>6.18</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3.56</td>\n",
       "      <td>12.67</td>\n",
       "      <td>4.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5756</th>\n",
       "      <td>119000</td>\n",
       "      <td>25.75</td>\n",
       "      <td>6.02</td>\n",
       "      <td>13.75</td>\n",
       "      <td>2.05</td>\n",
       "      <td>16.00</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5757</th>\n",
       "      <td>119250</td>\n",
       "      <td>31.50</td>\n",
       "      <td>3.35</td>\n",
       "      <td>10.25</td>\n",
       "      <td>5.12</td>\n",
       "      <td>16.25</td>\n",
       "      <td>2.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5758</th>\n",
       "      <td>119500</td>\n",
       "      <td>33.75</td>\n",
       "      <td>2.77</td>\n",
       "      <td>14.00</td>\n",
       "      <td>3.24</td>\n",
       "      <td>13.75</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5759</th>\n",
       "      <td>119750</td>\n",
       "      <td>37.00</td>\n",
       "      <td>1.41</td>\n",
       "      <td>18.25</td>\n",
       "      <td>3.70</td>\n",
       "      <td>11.00</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33117 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  var_rss23\n",
       "0          0      42.00       0.71      21.25       0.43      30.00       0.00\n",
       "1        250      41.50       0.50      20.25       1.48      31.25       1.09\n",
       "2        500      41.50       0.50      14.25       1.92      33.00       0.00\n",
       "3        750      40.75       0.83      15.75       0.43      33.00       0.00\n",
       "4       1000      40.00       0.71      20.00       2.74      32.75       0.43\n",
       "...      ...        ...        ...        ...        ...        ...        ...\n",
       "5755  118750      34.50       6.18       9.00       3.56      12.67       4.19\n",
       "5756  119000      25.75       6.02      13.75       2.05      16.00       1.58\n",
       "5757  119250      31.50       3.35      10.25       5.12      16.25       2.95\n",
       "5758  119500      33.75       2.77      14.00       3.24      13.75       0.43\n",
       "5759  119750      37.00       1.41      18.25       3.70      11.00       4.32\n",
       "\n",
       "[33117 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b8f6e9",
   "metadata": {},
   "source": [
    "c)\n",
    "Feature Extraction\n",
    "Classification of time series usually needs extracting features from them. In this\n",
    "problem, we focus on time-domain features.\n",
    "* i. Research what types of time-domain features are usually used in time series classification and list them (examples are minimum, maximum, mean, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c21fbb9",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "- Mean\n",
    "- Median\n",
    "- Standard Deviation\n",
    "- Variance\n",
    "- Minimum\n",
    "- Maximum\n",
    "- Range\n",
    "- Skewness\n",
    "- Kurtosis\n",
    "- Entropy\n",
    "- stationarity\n",
    "- scaling properties\n",
    "- 1st quartile\n",
    "- 3rd quartile\n",
    "- Interquartile Range (IQR)\n",
    "- Mean Absolute Deviation (MAD)\n",
    "- Coefficient of Variation (CV)\n",
    "- Hurst Exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ecb035",
   "metadata": {},
   "source": [
    "ii) Extract the time-domain features minimum, maximum, mean, median, stan-\n",
    "dard deviation, first quartile, and third quartile for all of the 6 time series\n",
    "in each instance. You are free to normalize/standardize features or use them\n",
    "directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cf12304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_min</th>\n",
       "      <th>1_max</th>\n",
       "      <th>1_mean</th>\n",
       "      <th>1_median</th>\n",
       "      <th>1_std</th>\n",
       "      <th>1_q1</th>\n",
       "      <th>1_q3</th>\n",
       "      <th>2_min</th>\n",
       "      <th>2_max</th>\n",
       "      <th>2_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>5_std</th>\n",
       "      <th>5_q1</th>\n",
       "      <th>5_q3</th>\n",
       "      <th>6_min</th>\n",
       "      <th>6_max</th>\n",
       "      <th>6_mean</th>\n",
       "      <th>6_median</th>\n",
       "      <th>6_std</th>\n",
       "      <th>6_q1</th>\n",
       "      <th>6_q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.25</td>\n",
       "      <td>45.00</td>\n",
       "      <td>40.624792</td>\n",
       "      <td>40.500</td>\n",
       "      <td>1.475428</td>\n",
       "      <td>39.25</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.358604</td>\n",
       "      <td>...</td>\n",
       "      <td>2.186168</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>36.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.570583</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.582308</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.00</td>\n",
       "      <td>45.67</td>\n",
       "      <td>42.812812</td>\n",
       "      <td>42.500</td>\n",
       "      <td>1.434054</td>\n",
       "      <td>42.00</td>\n",
       "      <td>43.6700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.372437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.993175</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>34.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.571083</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.600383</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.00</td>\n",
       "      <td>47.40</td>\n",
       "      <td>43.954500</td>\n",
       "      <td>44.330</td>\n",
       "      <td>1.557210</td>\n",
       "      <td>43.00</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.426250</td>\n",
       "      <td>...</td>\n",
       "      <td>1.997520</td>\n",
       "      <td>35.3625</td>\n",
       "      <td>36.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.493292</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.512971</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.00</td>\n",
       "      <td>47.75</td>\n",
       "      <td>42.179812</td>\n",
       "      <td>43.500</td>\n",
       "      <td>3.666840</td>\n",
       "      <td>39.15</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.696042</td>\n",
       "      <td>...</td>\n",
       "      <td>3.845436</td>\n",
       "      <td>30.4575</td>\n",
       "      <td>36.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.613521</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.523771</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.00</td>\n",
       "      <td>45.75</td>\n",
       "      <td>41.678063</td>\n",
       "      <td>41.750</td>\n",
       "      <td>2.241152</td>\n",
       "      <td>41.33</td>\n",
       "      <td>42.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.535979</td>\n",
       "      <td>...</td>\n",
       "      <td>2.408514</td>\n",
       "      <td>28.4575</td>\n",
       "      <td>31.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.383292</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.388759</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>20.75</td>\n",
       "      <td>46.25</td>\n",
       "      <td>34.763333</td>\n",
       "      <td>35.290</td>\n",
       "      <td>4.737266</td>\n",
       "      <td>31.67</td>\n",
       "      <td>38.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.68</td>\n",
       "      <td>4.223792</td>\n",
       "      <td>...</td>\n",
       "      <td>3.171372</td>\n",
       "      <td>14.2500</td>\n",
       "      <td>18.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.39</td>\n",
       "      <td>3.288271</td>\n",
       "      <td>3.270</td>\n",
       "      <td>1.645811</td>\n",
       "      <td>2.05</td>\n",
       "      <td>4.3050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>21.50</td>\n",
       "      <td>51.00</td>\n",
       "      <td>34.935812</td>\n",
       "      <td>35.500</td>\n",
       "      <td>4.641102</td>\n",
       "      <td>32.00</td>\n",
       "      <td>38.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.21</td>\n",
       "      <td>4.115750</td>\n",
       "      <td>...</td>\n",
       "      <td>3.188731</td>\n",
       "      <td>14.2375</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.21</td>\n",
       "      <td>3.280021</td>\n",
       "      <td>3.015</td>\n",
       "      <td>1.699145</td>\n",
       "      <td>2.12</td>\n",
       "      <td>4.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>18.33</td>\n",
       "      <td>47.67</td>\n",
       "      <td>34.333042</td>\n",
       "      <td>34.750</td>\n",
       "      <td>4.943612</td>\n",
       "      <td>31.25</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.48</td>\n",
       "      <td>4.396958</td>\n",
       "      <td>...</td>\n",
       "      <td>2.997366</td>\n",
       "      <td>13.7500</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.01</td>\n",
       "      <td>3.261583</td>\n",
       "      <td>2.980</td>\n",
       "      <td>1.615604</td>\n",
       "      <td>2.05</td>\n",
       "      <td>4.3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>18.33</td>\n",
       "      <td>45.75</td>\n",
       "      <td>34.599875</td>\n",
       "      <td>35.125</td>\n",
       "      <td>4.726858</td>\n",
       "      <td>31.50</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.37</td>\n",
       "      <td>4.398833</td>\n",
       "      <td>...</td>\n",
       "      <td>2.902659</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.86</td>\n",
       "      <td>3.289542</td>\n",
       "      <td>3.015</td>\n",
       "      <td>1.678418</td>\n",
       "      <td>2.12</td>\n",
       "      <td>4.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>15.50</td>\n",
       "      <td>43.67</td>\n",
       "      <td>34.225875</td>\n",
       "      <td>34.750</td>\n",
       "      <td>4.437168</td>\n",
       "      <td>31.25</td>\n",
       "      <td>37.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.24</td>\n",
       "      <td>4.354500</td>\n",
       "      <td>...</td>\n",
       "      <td>2.989801</td>\n",
       "      <td>14.3300</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.42</td>\n",
       "      <td>3.479542</td>\n",
       "      <td>3.270</td>\n",
       "      <td>1.759311</td>\n",
       "      <td>2.24</td>\n",
       "      <td>4.5375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1_min  1_max     1_mean  1_median     1_std   1_q1     1_q3  2_min  2_max  \\\n",
       "0   37.25  45.00  40.624792    40.500  1.475428  39.25  42.0000    0.0   1.30   \n",
       "1   38.00  45.67  42.812812    42.500  1.434054  42.00  43.6700    0.0   1.22   \n",
       "2   35.00  47.40  43.954500    44.330  1.557210  43.00  45.0000    0.0   1.70   \n",
       "3   33.00  47.75  42.179812    43.500  3.666840  39.15  45.0000    0.0   3.00   \n",
       "4   33.00  45.75  41.678063    41.750  2.241152  41.33  42.7500    0.0   2.83   \n",
       "..    ...    ...        ...       ...       ...    ...      ...    ...    ...   \n",
       "83  20.75  46.25  34.763333    35.290  4.737266  31.67  38.2500    0.0  12.68   \n",
       "84  21.50  51.00  34.935812    35.500  4.641102  32.00  38.0625    0.0  12.21   \n",
       "85  18.33  47.67  34.333042    34.750  4.943612  31.25  38.0000    0.0  12.48   \n",
       "86  18.33  45.75  34.599875    35.125  4.726858  31.50  38.0000    0.0  15.37   \n",
       "87  15.50  43.67  34.225875    34.750  4.437168  31.25  37.2500    0.0  17.24   \n",
       "\n",
       "      2_mean  ...     5_std     5_q1   5_q3  6_min  6_max    6_mean  6_median  \\\n",
       "0   0.358604  ...  2.186168  33.0000  36.00    0.0   1.92  0.570583     0.430   \n",
       "1   0.372437  ...  1.993175  32.0000  34.50    0.0   3.11  0.571083     0.430   \n",
       "2   0.426250  ...  1.997520  35.3625  36.50    0.0   1.79  0.493292     0.430   \n",
       "3   0.696042  ...  3.845436  30.4575  36.33    0.0   2.18  0.613521     0.500   \n",
       "4   0.535979  ...  2.408514  28.4575  31.25    0.0   1.79  0.383292     0.430   \n",
       "..       ...  ...       ...      ...    ...    ...    ...       ...       ...   \n",
       "83  4.223792  ...  3.171372  14.2500  18.33    0.0   9.39  3.288271     3.270   \n",
       "84  4.115750  ...  3.188731  14.2375  18.25    0.0  10.21  3.280021     3.015   \n",
       "85  4.396958  ...  2.997366  13.7500  18.00    0.0   8.01  3.261583     2.980   \n",
       "86  4.398833  ...  2.902659  14.0000  18.25    0.0   8.86  3.289542     3.015   \n",
       "87  4.354500  ...  2.989801  14.3300  18.25    0.0   9.42  3.479542     3.270   \n",
       "\n",
       "       6_std  6_q1    6_q3  \n",
       "0   0.582308  0.00  1.3000  \n",
       "1   0.600383  0.00  1.3000  \n",
       "2   0.512971  0.00  0.9400  \n",
       "3   0.523771  0.00  1.0000  \n",
       "4   0.388759  0.00  0.5000  \n",
       "..       ...   ...     ...  \n",
       "83  1.645811  2.05  4.3050  \n",
       "84  1.699145  2.12  4.5000  \n",
       "85  1.615604  2.05  4.3200  \n",
       "86  1.678418  2.12  4.2600  \n",
       "87  1.759311  2.24  4.5375  \n",
       "\n",
       "[88 rows x 42 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "def calculate_features(instance_df):\n",
    "    features = []\n",
    "    \n",
    "    for column in instance_df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(instance_df[column]):\n",
    "            feature_values = instance_df[column]\n",
    "            \n",
    "            min_val = np.min(feature_values)\n",
    "            max_val = np.max(feature_values)\n",
    "            mean_val = np.mean(feature_values)\n",
    "            median_val = np.median(feature_values)\n",
    "            std_val = np.std(feature_values)\n",
    "            q1_val = np.percentile(feature_values, 25)\n",
    "            q3_val = np.percentile(feature_values, 75)\n",
    "            \n",
    "            features.extend([min_val, max_val, mean_val, median_val, std_val, q1_val, q3_val])\n",
    "    \n",
    "    return features\n",
    "\n",
    "root_dir = '..\\AReM'\n",
    "\n",
    "columns = range(1, 100)\n",
    "feat_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for dataset_file in files:\n",
    "        if dataset_file.endswith('.csv'):\n",
    "            dataset_file_path = os.path.join(root, dataset_file)\n",
    "            \n",
    "            with open(dataset_file_path, 'r') as file:\n",
    "                sniffer = csv.Sniffer()\n",
    "                sep = sniffer.sniff(file.read()).delimiter\n",
    "                file.seek(0)\n",
    "                \n",
    "                if sep == \",\":\n",
    "                    instance_df = pd.read_csv(\n",
    "                        file,\n",
    "                        skiprows=5,\n",
    "                        header=None,\n",
    "                        on_bad_lines=\"skip\",\n",
    "                        index_col=None\n",
    "                    )\n",
    "                else:\n",
    "                    instance_df = pd.read_csv(\n",
    "                        file,\n",
    "                        skiprows=5,\n",
    "                        header=None,\n",
    "                        sep=\"\\s+\",\n",
    "                        on_bad_lines=\"skip\",\n",
    "                        index_col=None\n",
    "                    )\n",
    "            \n",
    "            instance_features = calculate_features(instance_df)\n",
    "            \n",
    "            feat_list.append(instance_features)\n",
    "\n",
    "feature_columns = []\n",
    "for col in instance_df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(instance_df[col]):\n",
    "        feature_columns.extend([f\"{col}_min\", f\"{col}_max\", f\"{col}_mean\", f\"{col}_median\", f\"{col}_std\", f\"{col}_q1\", f\"{col}_q3\"])\n",
    "\n",
    "features_df = pd.DataFrame(feat_list, columns=feature_columns)\n",
    "features_df = features_df.loc[:, ~features_df.columns.str.startswith('0_')]\n",
    "\n",
    "display(features_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "721b4d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1_min       9.569975\n",
       "1_max       4.394362\n",
       "1_mean      5.335700\n",
       "1_median    5.440054\n",
       "1_std       1.770338\n",
       "1_q1        6.153874\n",
       "1_q3        5.138925\n",
       "2_min       0.000000\n",
       "2_max       5.062729\n",
       "2_mean      1.574198\n",
       "2_median    1.412293\n",
       "2_std       0.883215\n",
       "2_q1        0.946386\n",
       "2_q3        2.125399\n",
       "3_min       2.956462\n",
       "3_max       4.875137\n",
       "3_mean      4.008228\n",
       "3_median    4.036396\n",
       "3_std       0.945683\n",
       "3_q1        4.220658\n",
       "3_q3        4.171628\n",
       "4_min       0.000000\n",
       "4_max       2.183625\n",
       "4_mean      1.166178\n",
       "4_median    1.145985\n",
       "4_std       0.457805\n",
       "4_q1        0.843405\n",
       "4_q3        1.552504\n",
       "5_min       6.124001\n",
       "5_max       5.741238\n",
       "5_mean      5.675543\n",
       "5_median    5.813782\n",
       "5_std       1.023850\n",
       "5_q1        6.096465\n",
       "5_q3        5.531720\n",
       "6_min       0.045838\n",
       "6_max       2.518921\n",
       "6_mean      1.154889\n",
       "6_median    1.086474\n",
       "6_std       0.517112\n",
       "6_q1        0.758687\n",
       "6_q3        1.523739\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec8a7af",
   "metadata": {},
   "source": [
    "iii.\n",
    "Estimate the standard deviation of each of the time-domain features you\n",
    "extracted from the data. Then, use Python’s bootstrapped or any other\n",
    "method to build a 90% bootsrap confidence interval for the standard deviation\n",
    "of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74a7f7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lower Bound</th>\n",
       "      <th>Upper Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1_min</th>\n",
       "      <td>8.235149</td>\n",
       "      <td>10.763278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_max</th>\n",
       "      <td>3.318860</td>\n",
       "      <td>5.256214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_mean</th>\n",
       "      <td>4.694834</td>\n",
       "      <td>5.858370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_median</th>\n",
       "      <td>4.781237</td>\n",
       "      <td>6.003624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_std</th>\n",
       "      <td>1.572356</td>\n",
       "      <td>1.932152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_q1</th>\n",
       "      <td>5.573038</td>\n",
       "      <td>6.668727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_q3</th>\n",
       "      <td>4.343051</td>\n",
       "      <td>5.801617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_max</th>\n",
       "      <td>4.605395</td>\n",
       "      <td>5.379246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_mean</th>\n",
       "      <td>1.394192</td>\n",
       "      <td>1.702588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_median</th>\n",
       "      <td>1.237880</td>\n",
       "      <td>1.539473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_std</th>\n",
       "      <td>0.801950</td>\n",
       "      <td>0.937596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_q1</th>\n",
       "      <td>0.829925</td>\n",
       "      <td>1.033832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_q3</th>\n",
       "      <td>1.885438</td>\n",
       "      <td>2.285915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_min</th>\n",
       "      <td>2.753058</td>\n",
       "      <td>3.104253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_max</th>\n",
       "      <td>4.193121</td>\n",
       "      <td>5.428565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_mean</th>\n",
       "      <td>3.409211</td>\n",
       "      <td>4.507045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_median</th>\n",
       "      <td>3.413076</td>\n",
       "      <td>4.564069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_std</th>\n",
       "      <td>0.765000</td>\n",
       "      <td>1.120231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_q1</th>\n",
       "      <td>3.624485</td>\n",
       "      <td>4.721640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_q3</th>\n",
       "      <td>3.552575</td>\n",
       "      <td>4.729324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_max</th>\n",
       "      <td>1.960208</td>\n",
       "      <td>2.345154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_mean</th>\n",
       "      <td>1.078077</td>\n",
       "      <td>1.221229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_median</th>\n",
       "      <td>1.056152</td>\n",
       "      <td>1.201114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_std</th>\n",
       "      <td>0.419982</td>\n",
       "      <td>0.486632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_q1</th>\n",
       "      <td>0.772754</td>\n",
       "      <td>0.889567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_q3</th>\n",
       "      <td>1.436032</td>\n",
       "      <td>1.626713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_min</th>\n",
       "      <td>4.327345</td>\n",
       "      <td>7.478028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_max</th>\n",
       "      <td>4.707473</td>\n",
       "      <td>6.555172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_mean</th>\n",
       "      <td>4.341710</td>\n",
       "      <td>6.683945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_median</th>\n",
       "      <td>4.445555</td>\n",
       "      <td>6.892007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_std</th>\n",
       "      <td>0.808645</td>\n",
       "      <td>1.218985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_q1</th>\n",
       "      <td>4.732577</td>\n",
       "      <td>7.163980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_q3</th>\n",
       "      <td>4.296472</td>\n",
       "      <td>6.502025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_max</th>\n",
       "      <td>2.237672</td>\n",
       "      <td>2.757582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_mean</th>\n",
       "      <td>1.061999</td>\n",
       "      <td>1.212841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_median</th>\n",
       "      <td>0.996973</td>\n",
       "      <td>1.146409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_std</th>\n",
       "      <td>0.479990</td>\n",
       "      <td>0.545177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_q1</th>\n",
       "      <td>0.690095</td>\n",
       "      <td>0.805456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_q3</th>\n",
       "      <td>1.403967</td>\n",
       "      <td>1.599926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Lower Bound  Upper Bound\n",
       "1_min        8.235149    10.763278\n",
       "1_max        3.318860     5.256214\n",
       "1_mean       4.694834     5.858370\n",
       "1_median     4.781237     6.003624\n",
       "1_std        1.572356     1.932152\n",
       "1_q1         5.573038     6.668727\n",
       "1_q3         4.343051     5.801617\n",
       "2_min        0.000000     0.000000\n",
       "2_max        4.605395     5.379246\n",
       "2_mean       1.394192     1.702588\n",
       "2_median     1.237880     1.539473\n",
       "2_std        0.801950     0.937596\n",
       "2_q1         0.829925     1.033832\n",
       "2_q3         1.885438     2.285915\n",
       "3_min        2.753058     3.104253\n",
       "3_max        4.193121     5.428565\n",
       "3_mean       3.409211     4.507045\n",
       "3_median     3.413076     4.564069\n",
       "3_std        0.765000     1.120231\n",
       "3_q1         3.624485     4.721640\n",
       "3_q3         3.552575     4.729324\n",
       "4_min        0.000000     0.000000\n",
       "4_max        1.960208     2.345154\n",
       "4_mean       1.078077     1.221229\n",
       "4_median     1.056152     1.201114\n",
       "4_std        0.419982     0.486632\n",
       "4_q1         0.772754     0.889567\n",
       "4_q3         1.436032     1.626713\n",
       "5_min        4.327345     7.478028\n",
       "5_max        4.707473     6.555172\n",
       "5_mean       4.341710     6.683945\n",
       "5_median     4.445555     6.892007\n",
       "5_std        0.808645     1.218985\n",
       "5_q1         4.732577     7.163980\n",
       "5_q3         4.296472     6.502025\n",
       "6_min        0.000000     0.078476\n",
       "6_max        2.237672     2.757582\n",
       "6_mean       1.061999     1.212841\n",
       "6_median     0.996973     1.146409\n",
       "6_std        0.479990     0.545177\n",
       "6_q1         0.690095     0.805456\n",
       "6_q3         1.403967     1.599926"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def compute_bootstrap_intervals(dataset, iterations, percentile_low, percentile_high):\n",
    "    bootstrap_std_devs = []\n",
    "\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        bootstrap_sample = resample(dataset, replace=True, n_samples=len(dataset))\n",
    "        bootstrap_std = bootstrap_sample.std()\n",
    "        bootstrap_std_devs.append(bootstrap_std)\n",
    "\n",
    "   \n",
    "    std_devs_df = pd.DataFrame(bootstrap_std_devs)\n",
    "\n",
    "    \n",
    "    lower_bounds = std_devs_df.apply(lambda x: np.percentile(x, percentile_low), axis=0)\n",
    "    upper_bounds = std_devs_df.apply(lambda x: np.percentile(x, percentile_high), axis=0)\n",
    "\n",
    "    \n",
    "    confidence_interval_df = pd.DataFrame({\n",
    "        'Lower Bound': lower_bounds,\n",
    "        'Upper Bound': upper_bounds\n",
    "    })\n",
    "\n",
    "    return confidence_interval_df\n",
    "\n",
    "bootstrap_confidence_intervals = compute_bootstrap_intervals(features_df, 1000, 5, 95)\n",
    "display(bootstrap_confidence_intervals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3a4fd2",
   "metadata": {},
   "source": [
    "### iv.Use your judgement to select the three most important time-domain features (one option may be min, mean, and max)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd472d1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Mean:** This represents the average value of the dataset, providing a central point that indicates the general tendency of the data points. The mean is useful for understanding the overall level of the measured variable and is often used in conjunction with other metrics to provide a more complete picture of the data's characteristics.\n",
    "\n",
    "**Maximum:** This indicates the highest value in the dataset, which can be crucial for identifying peaks or extreme values. The maximum value is particularly important in contexts where outliers or peak performance metrics are of interest, as it helps to understand the upper limits of the data.\n",
    "\n",
    "**Third Quartile (Q3):** The third quartile represents the value below which 75% of the data falls. It provides insights into the upper range of the data distribution and can help identify higher percentile behavior.\n",
    "\n",
    "**Standard Deviation:** This measures the dispersion or variability of the dataset. A higher standard deviation indicates that the data points are spread out over a larger range of values, which can be important for understanding the volatility or consistency of the data.\n",
    "\n",
    "**Skewness:** This measures the asymmetry of the data distribution around its mean. Positive skew indicates a distribution with an asymmetric tail extending towards more positive values, while negative skew indicates a tail extending towards more negative values. Skewness can provide insights into the nature of the distribution of observed values, which can be crucial for certain types of statistical analysis where normal distribution is assumed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ffef6",
   "metadata": {},
   "source": [
    "# 2. ISLR 3.7.4\n",
    "### I collect a set of data (n = 100 observations) containing a single predictor and a quantitative response. I then fit a linear regression model to the data, as well as a separate cubic regression, i.e. Y = β0 + β1X + β2X2 + β3X3 + ϵ. \n",
    "### (a) Suppose that the true relationship between X and Y is linear, i.e. Y = β0 + β1X + ϵ. Consider the training residual sum of squares (RSS) for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.\n",
    "### (b) Answer (a) using test rather than training RSS.\n",
    "### (c) Suppose that the true relationship between X and Y is not linear,but we don’t know how far it is from linear. Consider the trainingRSS for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.\n",
    "### (d) Answer (c) using test rather than training RSS.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ca994",
   "metadata": {},
   "source": [
    "\n",
    "### Part (a): Training RSS for Linear vs. Cubic Regression with a Linear True Relationship\n",
    "\n",
    "Given a true linear relationship between $X$ and $Y$, the training RSS for a linear regression model directly reflects the variance in the data that is not explained by the linear model. In contrast, a cubic regression ($Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\beta_3X^3 + \\epsilon$) can potentially fit the training data more closely due to its additional parameters, allowing for a lower training RSS. However, this does not imply that cubic regression is more appropriate; it merely has greater flexibility, which may lead to overfitting, especially if the true underlying relationship is indeed linear.\n",
    "\n",
    "### Part (b): Test RSS for Linear vs. Cubic Regression with a Linear True Relationship\n",
    "\n",
    "When evaluating the model's performance on unseen data (test RSS), the simpler linear regression model is expected to outperform the cubic regression if the true relationship is linear. This is because the cubic regression's added complexity, while potentially reducing training RSS, is likely to result in overfitting, capturing noise in the training data as if it were a true signal. Consequently, the linear model, being more aligned with the true linear relationship, is expected to generalize better, leading to a lower test RSS.\n",
    "\n",
    "### Part (c): Training RSS for Linear vs. Cubic Regression with a Nonlinear True Relationship\n",
    "\n",
    "If the true relationship between $X$ and $Y$ is nonlinear, the training RSS comparison between linear and cubic regression models becomes contingent on the nature of the nonlinearity. The cubic regression's flexibility enables it to model complex relationships more effectively, likely resulting in a lower training RSS compared to the linear model. This assumes that the nonlinearity in the true relationship can be better captured by the cubic model's additional terms.\n",
    "\n",
    "### Part (d): Test RSS for Linear vs. Cubic Regression with a Nonlinear True Relationship\n",
    "\n",
    "For a nonlinear true relationship, the test RSS will critically depend on the model's ability to generalize beyond the training data. The cubic regression may offer a better fit for the training data and, if the nonlinearity it models is reflective of the true relationship, could potentially lead to a lower test RSS. However, the risk of overfitting remains significant; if the cubic model captures noise as signal, its performance on new data may degrade. Conversely, a linear model, despite possibly having a higher bias for assuming linearity, might exhibit lower variance and better generalization to new data, particularly if the true relationship's deviation from linearity is modest.\n",
    "\n",
    "In essence, the choice between a linear and cubic model for both training and test RSS should be informed by the underlying relationship's complexity and the models' respective bias-variance trade-offs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb74bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
